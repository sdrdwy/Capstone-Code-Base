#!/usr/bin/env python3
"""
ä¸­è¥¿åŒ»ç»“åˆé—®è¯Šç³»ç»Ÿ - Gradio UI ç‰ˆæœ¬
"""

import os
import sys
from typing import List, Dict, Any, Tuple
from dotenv import load_dotenv
from langchain_community.chat_models import ChatTongyi
from langchain_chroma import Chroma
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_neo4j import Neo4jGraph
import gradio as gr

# ä¿æŒä¸ main.py å®Œå…¨ä¸€è‡´çš„ç›¸å¯¹å¯¼å…¥
from .agents.west_agent import WestAgent
from .agents.tcm_agent import TcmAgent
from .agents.supervisor_agent import SupervisorAgent
from .agents.final_agent import FinalAgent
from .utils.query_fix import fix_query


# ==================== å…¨å±€çŠ¶æ€å°è£… ====================
class AppState:
    def __init__(self):
        self.llm = None
        self.west_agent = None
        self.tcm_agent = None
        self.final_agent = None
        self.supervisor_agent = None
        self.tcm_vectorstore = None
        self.enable_advice = True
        self.conversation_ended = False
        self.last_tcm_response = {}
        self.last_west_response = {}
        self.last_supervisor_output = ""

    def initialize(self):
        load_dotenv()
        self.llm = ChatTongyi(model="qwen-max", temperature=0.1)
        graph = Neo4jGraph(database=os.environ["DB_NAME"])
        embedding = DashScopeEmbeddings(model="text-embedding-v2")
        embedding_v3 = DashScopeEmbeddings(model="text-embedding-v3")

        west_vectorstore = Chroma(
            persist_directory="./chroma_db_dash_w",
            embedding_function=embedding
        )
        tcm_vectorstore = Chroma(
            persist_directory="basic_app/chroma_db_embedding",
            embedding_function=embedding,
        )
        tcm_med_vectorstore = Chroma(
            persist_directory="chroma_TCM_rag_db_qwen",
            embedding_function=embedding_v3,
            collection_name="medical_book_qwen"
        )

        self.west_agent = WestAgent(llm=self.llm, retriever=west_vectorstore.as_retriever())
        self.tcm_agent = TcmAgent(llm=self.llm, graph=graph, retriever=tcm_med_vectorstore.as_retriever())
        self.final_agent = FinalAgent(llm=self.llm)
        self.supervisor_agent = SupervisorAgent(llm=self.llm)
        self.tcm_vectorstore = tcm_vectorstore

        self.conversation_ended = False
        self.last_tcm_response = {}
        self.last_west_response = {}
        self.last_supervisor_output = ""

    def reset(self):
        if self.final_agent:
            self.final_agent.reset_conversation()
        self.conversation_ended = False
        self.last_supervisor_output = ""
        self.last_tcm_response = {}
        self.last_west_response = {}


# å®ä¾‹åŒ–å…¨å±€çŠ¶æ€
app_state = AppState()


# ==================== æ ¸å¿ƒäº¤äº’å‡½æ•° ====================
def format_docs(docs: List[Any]) -> str:
    if not docs:
        return "ï¼ˆæ— æ£€ç´¢ç»“æœï¼‰"
    texts = [doc.page_content if hasattr(doc, 'page_content') else str(doc) for doc in docs]
    return "\n\n---\n\n".join(texts)


def process_user_input(user_input: str, chat_history: List[Tuple[str, str]]) -> Tuple[
    List[Tuple[str, str]], str, str, str, str, str, str, bool]:
    """
    å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶è¿”å›æ‰€æœ‰ UI ç»„ä»¶æ›´æ–°
    """
    if app_state.conversation_ended:
        gr.Info("å½“å‰é—®è¯Šå·²ç»“æŸï¼Œè¯·ç‚¹å‡»â€œé‡ç½®â€å¼€å§‹æ–°å¯¹è¯ã€‚")
        return chat_history, "", "", "", "", "", "", True

    if not user_input.strip():
        return chat_history, "", "", "", "", "", "", False

    try:
        # 1. Fix query
        fixed_query = fix_query(user_input, app_state.llm, app_state.tcm_vectorstore, 10)['query']

        # 2. å¹¶è¡ŒæŸ¥è¯¢ä¸­è¥¿åŒ» Agent
        west_response = app_state.west_agent.query(user_input,app_state.final_agent.conversation_history)
        tcm_response = app_state.tcm_agent.query(fixed_query,app_state.final_agent.conversation_history)

        app_state.last_west_response = west_response
        app_state.last_tcm_response = tcm_response

        # 3. FinalAgent ç”ŸæˆåŒ»ç”Ÿå›å¤
        final_response = app_state.final_agent.process_input(
            patient_input=user_input,
            advice=app_state.last_supervisor_output if app_state.enable_advice else ""
        )
        doctor_reply = final_response['response']
        is_ended = final_response['is_ended']

        # æ›´æ–°èŠå¤©å†å²
        chat_history.append((user_input, doctor_reply))

        # 4. Supervisor è¯„ä¼°
        conversation_history = "\n".join(app_state.final_agent.conversation_history)
        supervision_result = app_state.supervisor_agent.evaluate_conversation(
            conversation_history,
            tcm_response['result'],
            west_response['result']
        )

        if app_state.enable_advice and supervision_result.get('should_advise') and supervision_result.get('advice'):
            app_state.last_supervisor_output = supervision_result['advice']
        else:
            app_state.last_supervisor_output = ""

        # 5. æ£€æŸ¥æ˜¯å¦ç»“æŸ
        if is_ended:
            app_state.conversation_ended = True
            analysis = app_state.supervisor_agent.analyze_diagnosis_process(app_state.final_agent.conversation_history)
            chat_history.append((None, f"**ã€é—®è¯Šç»“æŸã€‘**\n\n{analysis}"))

        # è¿”å›æ‰€æœ‰ UI æ›´æ–°
        return (
            chat_history,
            app_state.last_supervisor_output or "(æ— å»ºè®®)",
            west_response['result'],
            tcm_response['result'],
            # format_docs(tcm_response.get('retrieved_docs', [])),
            tcm_response.get('retrieved_docs', []),
            format_docs(west_response.get('retrieved_docs', [])),
            str(tcm_response.get('graph', 'ï¼ˆæ— å›¾è°±ç»“æœï¼‰')),
            app_state.conversation_ended
        )

    except Exception as e:
        error_msg = f"âŒ é”™è¯¯: {str(e)}"
        chat_history.append((user_input, error_msg))
        return chat_history, error_msg, error_msg, error_msg, error_msg, error_msg, error_msg, True


def end_conversation(chat_history: List[Tuple[str, str]]) -> Tuple[List[Tuple[str, str]], bool]:
    if app_state.conversation_ended:
        return chat_history, True
    if not app_state.final_agent.conversation_history:
        gr.Info("å°šæœªå¼€å§‹é—®è¯Šã€‚")
        return chat_history, False

    analysis = app_state.supervisor_agent.analyze_diagnosis_process(app_state.final_agent.conversation_history)
    chat_history.append((None, f"**ã€å¼ºåˆ¶ç»“æŸ - é—®è¯Šæ€»ç»“ã€‘**\n\n{analysis}"))
    app_state.conversation_ended = True
    return chat_history, True


def toggle_advice(enable: bool) -> bool:
    app_state.enable_advice = enable
    return enable


def reset_conversation() -> Tuple[List, str, str, str, str, str, str, bool, bool]:
    app_state.reset()
    return [], "", "", "", "", "", "", False, False


# ==================== Gradio UI æ„å»º ====================
with gr.Blocks(title="ä¸­è¥¿åŒ»ç»“åˆæ™ºèƒ½é—®è¯Šç³»ç»Ÿ") as demo:
    gr.Markdown("## ğŸ¥ ä¸­è¥¿åŒ»ç»“åˆæ™ºèƒ½é—®è¯Šç³»ç»Ÿ")
    gr.Markdown("è¾“å…¥æ‚¨çš„ç—‡çŠ¶ï¼Œç³»ç»Ÿå°†å¹¶è¡Œè°ƒç”¨ä¸­è¥¿åŒ»çŸ¥è¯†åº“ï¼Œå¹¶ç”± AI åŒ»ç”Ÿé€æ­¥é—®è¯Šã€‚")

    with gr.Row():
        # ========== å·¦ä¾§ï¼šæ£€ç´¢ç»“æœ ==========
        with gr.Column(scale=2):
            gr.Markdown("### ğŸ“š ä¸­åŒ»çŸ¥è¯†åº“ (RAG)")
            tcm_rag_output = gr.Textbox(label="ä¸­åŒ» RAG æ£€ç´¢ç»“æœ", lines=10, interactive=False)
            gr.Markdown("### ğŸ“š è¥¿åŒ»çŸ¥è¯†åº“ (RAG)")
            west_rag_output = gr.Textbox(label="è¥¿åŒ» RAG æ£€ç´¢ç»“æœ", lines=10, interactive=False)
            gr.Markdown("### ğŸ§  ä¸­åŒ» GraphRAG")
            tcm_graph_output = gr.Textbox(label="ä¸­åŒ»å›¾è°±æŸ¥è¯¢ç»“æœ", lines=10, interactive=False)

        # ========== ä¸­é—´ï¼šChatbot ==========
        with gr.Column(scale=3):
            chatbot = gr.Chatbot(
                height=600,
                avatar_images=("assets/patient.png", "assets/doctor.png"),  # å¯é€‰
                show_label=False
            )
            user_input = gr.Textbox(
                placeholder="è¯·è¾“å…¥æ‚¨çš„ç—‡çŠ¶ï¼Œä¾‹å¦‚ï¼š'æœ€è¿‘æ€»æ˜¯å¤´æ™•ä¹åŠ›'...",
                label="æ‚£è€…è¾“å…¥",
                container=False
            )
            with gr.Row():
                submit_btn = gr.Button("å‘é€", variant="primary")
                reset_btn = gr.Button("é‡ç½®å¯¹è¯")

        # ========== å³ä¾§ï¼šAgent è¾“å‡º ==========
        with gr.Column(scale=2):
            gr.Markdown("### ğŸ‘¨â€ğŸ« ä¸“å®¶å»ºè®® (Supervisor)")
            supervisor_output = gr.Textbox(label="å»ºè®®å†…å®¹", lines=4, interactive=False)
            gr.Markdown("### ğŸ©º è¥¿åŒ» Agent è¾“å‡º")
            west_output = gr.Textbox(label="è¥¿åŒ»åˆ†æ", lines=8, interactive=False)
            gr.Markdown("### ğŸŒ¿ ä¸­åŒ» Agent è¾“å‡º")
            tcm_output = gr.Textbox(label="ä¸­åŒ»åˆ†æ", lines=8, interactive=False)

    # ========== åº•éƒ¨æ§åˆ¶ ==========
    with gr.Row():
        end_btn = gr.Button("ç»“æŸå¯¹è¯å¹¶æ€»ç»“", variant="stop")
        advice_toggle = gr.Checkbox(label="å¯ç”¨ä¸“å®¶å»ºè®®", value=True)

    # ========== çŠ¶æ€å˜é‡ ==========
    conversation_ended_state = gr.State(False)

    # ========== äº‹ä»¶ç»‘å®š ==========
    submit_event = user_input.submit(
        fn=process_user_input,
        inputs=[user_input, chatbot],
        outputs=[
            chatbot,
            supervisor_output,
            west_output,
            tcm_output,
            tcm_rag_output,
            west_rag_output,
            tcm_graph_output,
            conversation_ended_state
        ],
        show_progress="full"
    ).then(lambda: "", None, user_input)  # æ¸…ç©ºè¾“å…¥æ¡†

    submit_btn.click(
        fn=process_user_input,
        inputs=[user_input, chatbot],
        outputs=[
            chatbot,
            supervisor_output,
            west_output,
            tcm_output,
            tcm_rag_output,
            west_rag_output,
            tcm_graph_output,
            conversation_ended_state
        ],
        show_progress="full"
    ).then(lambda: "", None, user_input)

    end_btn.click(
        fn=end_conversation,
        inputs=[chatbot],
        outputs=[chatbot, conversation_ended_state]
    )

    advice_toggle.change(
        fn=toggle_advice,
        inputs=advice_toggle,
        outputs=advice_toggle
    )

    reset_btn.click(
        fn=reset_conversation,
        inputs=[],
        outputs=[
            chatbot,
            supervisor_output,
            west_output,
            tcm_output,
            tcm_rag_output,
            west_rag_output,
            tcm_graph_output,
            conversation_ended_state,
            advice_toggle
        ]
    )

    # ========== åˆå§‹åŒ– ==========
    demo.load(
        fn=lambda: None,
        inputs=None,
        outputs=None,
        # _js="() => { document.title = 'ä¸­è¥¿åŒ»ç»“åˆé—®è¯Šç³»ç»Ÿ'; }"
    )


# ==================== å¯åŠ¨å…¥å£ ====================
if __name__ == "__main__":
    # ä¸ main.py ä¸€è‡´çš„å‚æ•°å¤„ç†
    enable_advice_default = True
    if "--disable" in sys.argv:
        enable_advice_default = False

    app_state.enable_advice = enable_advice_default
    app_state.initialize()

    demo.launch(
        server_name="127.0.0.1",
        server_port=7860,
        share=False,
        show_error=True
    )