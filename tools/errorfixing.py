import os
import time
import json
from openai import OpenAI

# ======================
# é…ç½®åŒºï¼ˆè¯·æŒ‰å®é™…æƒ…å†µä¿®æ”¹ï¼‰
# ======================
INPUT_FILE = "çš®è‚¤ç—…ä¸­åŒ»è¯Šç–—å­¦.txt"          # åŸå§‹å«é”™å­—æ–‡æœ¬
OUTPUT_FILE = "ocr_corrected.txt"   # ä¿®æ­£åè¾“å‡º
CHECKPOINT_FILE = "progress.json"   # è¿›åº¦ä¿å­˜

# æ›¿æ¢ä¸ºä½ çš„ Gemini 2.5 Flash çš„ OpenAI å…¼å®¹ endpoint å’Œ API Key
# ä¾‹å¦‚ï¼šGoogle AI Studio çš„ OpenAI å…¼å®¹åœ°å€
BASE_URL = "https://generativelanguage.googleapis.com/v1beta/openai/"
API_KEY = ""

MODEL_NAME = "gemini-2.5-flash-lite"     # ç¡®ä¿æ¨¡å‹åæ­£ç¡®

# åˆ†å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼Œçº¦ 300â€“500 tokensï¼‰
MAX_CHARS_PER_CHUNK = 800

# è°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰ï¼Œé˜²æ­¢è§¦å‘é€Ÿç‡é™åˆ¶
REQUEST_DELAY = 5  # Gemini Flash å…è´¹ tier å»ºè®® â‰¥0.5s

# ======================
# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
# ======================
client = OpenAI(
    api_key=API_KEY,
    base_url=BASE_URL,
)

# ======================
# æ–‡æœ¬åˆ†å—å‡½æ•°
# ======================
def split_text(text, max_chars=MAX_CHARS_PER_CHUNK):
    paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
    chunks = []
    current = ""
    for p in paragraphs:
        if len(current) + len(p) + 2 <= max_chars:
            current += "\n\n" + p if current else p
        else:
            if current:
                chunks.append(current)
            current = p
    if current:
        chunks.append(current)
    return chunks

# ======================
# è°ƒç”¨ LLM ä¿®æ­£å•ä¸ª chunk
# ======================
def correct_chunk(chunk: str) -> str:
    prompt = f"""ä½ æ˜¯ä¸€åä¸­è¥¿åŒ»ç»“åˆåŒ»å­¦æ–‡çŒ®æ ¡å¯¹ä¸“å®¶ã€‚è¯·ä¸¥æ ¼ä¿®æ­£ä»¥ä¸‹æ–‡æœ¬ä¸­çš„ OCR é”™åˆ«å­—ã€ä¹±ç æˆ–æ˜æ˜¾è¯†åˆ«é”™è¯¯ï¼Œä½†ä¸å¾—æ”¹å˜åŸæ„ã€ä¸å¾—åˆ å‡å†…å®¹ã€ä¸å¾—æ·»åŠ è§£é‡Šã€‚ä»…è¾“å‡ºä¿®æ­£åçš„çº¯æ–‡æœ¬ã€‚

åŸæ–‡ï¼š
{chunk}

ä¿®æ­£åï¼š
"""
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "user", "content": prompt}
            ],
        
            temperature=0.0,          # ç¡®å®šæ€§è¾“å‡º
            # max_tokens=1000,
            # timeout=30.0
        )
        corrected = response.choices[0].message.content.strip()
        # print(corrected)
        return corrected
    except Exception as e:
        print(f"[ERROR] {e}")
        return chunk  # å‡ºé”™æ—¶è¿”å›åŸæ–‡ï¼Œé¿å…ä¸¢å¤±

# ======================
# ä¸»å¤„ç†æµç¨‹
# ======================
def main():
    # è¯»å–åŸå§‹æ–‡æœ¬
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        raw_text = f.read()
    chunks = split_text(raw_text, MAX_CHARS_PER_CHUNK)
    print(f"å…±åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªæ–‡æœ¬å—")

    # åŠ è½½è¿›åº¦ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
    if os.path.exists(CHECKPOINT_FILE):
        with open(CHECKPOINT_FILE, 'r', encoding='utf-8') as f:
            progress = json.load(f)
        start_idx = progress.get("last_index", -1) + 1
        corrected_list = progress.get("corrected", [])
        print(f"ä»ç¬¬ {start_idx + 1} å—ç»§ç»­å¤„ç†")
    else:
        start_idx = 0
        corrected_list = []

    # æ‰¹é‡å¤„ç†
    for i in range(start_idx, len(chunks)):
        print(f"å¤„ç†ç¬¬ {i+1}/{len(chunks)} å—...")
        corrected = correct_chunk(chunks[i])
        corrected_list.append(corrected)

        # æ¯ 10 å—ä¿å­˜ä¸€æ¬¡è¿›åº¦å’Œä¸­é—´ç»“æœ
        if (i + 1) % 10 == 0:
            with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
                f.write('\n\n'.join(corrected_list))
            with open(CHECKPOINT_FILE, 'w', encoding='utf-8') as f:
                json.dump({
                    "last_index": i,
                    "corrected": corrected_list
                }, f, ensure_ascii=False, indent=2)
            print(f"âœ… å·²ä¿å­˜è‡³ç¬¬ {i+1} å—")

        time.sleep(REQUEST_DELAY)  # æ§åˆ¶è¯·æ±‚é¢‘ç‡

    # æœ€ç»ˆä¿å­˜
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write('\n\n'.join(corrected_list))
    if os.path.exists(CHECKPOINT_FILE):
        os.remove(CHECKPOINT_FILE)
    print("ğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    main()